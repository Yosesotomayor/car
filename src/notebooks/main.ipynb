{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740e4953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check completed!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "from lib.check import check_paths\n",
    "paths = check_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca800e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # .jpeg to .pdf converter\n",
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# image = Image.open(paths['data_path']/'Image.jpeg')\n",
    "# pdf_path = paths['out_path']/'Image.pdf'\n",
    "# image.save(pdf_path, 'PDF', resolution=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4e2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PyPDF2 import PdfReader\n",
    "# pdf = PdfReader(paths['data_path']/'comprobante.pdf')\n",
    "# text = \"\"\n",
    "# for page in pdf.pages:\n",
    "#     text += page.extract_text()\n",
    "# if \"CFE\" in text:\n",
    "#     try:\n",
    "#         parts = text.split(\"Servicios B\u00e1sicos\")\n",
    "#         if len(parts) > 1:\n",
    "#             address_block = parts[1].strip()\n",
    "#             lines = [line.strip() for line in address_block.split('\\n') if line.strip()]\n",
    "            \n",
    "#             if len(lines) >= 2:\n",
    "#                 line0 = lines[0]\n",
    "#                 line1 = \"\".join(lines[1].split(\",\")[1:2]).strip()\n",
    "#                 import re\n",
    "#                 line1 = re.sub(r'[^\\d]', '', line1)\n",
    "#                 line2 = lines[2] if len(lines) > 2 else \"\"\n",
    "\n",
    "#                 if \", colonia\" in line0:\n",
    "#                     street, colony = line0.split(\", colonia\")\n",
    "#                     colony = \"colonia\" + colony\n",
    "#                 else:\n",
    "#                     street = line0\n",
    "#                     colony = \"\"\n",
    "                \n",
    "#                 cp_line = line1\n",
    "                \n",
    "#                 city = line2.split(\".\")[0]\n",
    "                \n",
    "#                 domicile = [street.strip(), colony.strip(', '), cp_line.strip(', '), city.strip()]\n",
    "#                 print(\"Found Domicile from PDF:\")\n",
    "#                 print(f\"Street: {domicile[0]}\")\n",
    "#                 print(f\"Colony: {domicile[1]}\")\n",
    "#                 print(f\"CP Line: {domicile[2]}\")\n",
    "#                 print(f\"City: {domicile[3]}\")\n",
    "#             else:\n",
    "#                  print(\"Address lines not found in expected format.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error parsing address: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domicile_extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import pytesseract\n",
    "\n",
    "# try:\n",
    "#     image_path = paths['data_path'] / 'Image.jpeg'\n",
    "#     image = Image.open(image_path)\n",
    "#     text = pytesseract.image_to_string(image)\n",
    "#     #print(text)\n",
    "\n",
    "#     lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "#     domicile = []\n",
    "\n",
    "#     for i, line in enumerate(lines):\n",
    "#         if \"C.P.\" in line:\n",
    "#             if i >= 2:\n",
    "#                 street = lines[i-2].split('|')[0].strip()\n",
    "#                 colony = lines[i-1]\n",
    "#                 cp_city = \" \".join(line.split(' ')[1:2]).strip().rstrip(\",\")\n",
    "                \n",
    "#                 city = \"\"\n",
    "#                 if i + 1 < len(lines) and \"Estado de cuenta\" not in lines[i+1]:\n",
    "#                      city = lines[i+1]\n",
    "#                 elif i + 2 < len(lines) and \"Estado de cuenta\" not in lines[i+2]:\n",
    "#                      city = \" \".join(lines[i+2].split(' ')[1:3])\n",
    "                \n",
    "#                 domicile = [street, colony, cp_city, city]\n",
    "#                 print(\"Found Domicile:\")\n",
    "#                 print(f\"Street: {street}\")\n",
    "#                 print(f\"Colony: {colony}\")\n",
    "#                 print(f\"CP Line: {cp_city}\")\n",
    "#                 print(f\"City: {city}\")\n",
    "#                 break\n",
    "    \n",
    "#     if not domicile:\n",
    "#         print(\"Could not find domicile (C.P. anchor).\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0214c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from structocr import StructOCR\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "# client = StructOCR(os.getenv(\"STRUCT_OCR_API_KEY\"))\n",
    "\n",
    "# def scan_mexico_id():\n",
    "#     image_path = paths[\"data_path\"]/\"ine zai.pdf\"\n",
    "#     # pdf to image\n",
    "#     from pdf2image import convert_from_path\n",
    "#     pages = convert_from_path(image_path)\n",
    "#     for i, page in enumerate(pages):\n",
    "#         page.save(paths[\"out_path\"]/f\"ine_{i}.jpeg\", 'JPEG')\n",
    "#     try:\n",
    "#         print(f\"Scanning {image_path}...\")\n",
    "        \n",
    "#         result = client.scan_national_id(paths[\"out_path\"]/f\"ine_0.jpeg\")\n",
    "\n",
    "#         if result.get('success'):\n",
    "#             data = result['data']\n",
    "#             print(\"M\u00e9xico Extraction Successful!\")\n",
    "            \n",
    "#             print(f\"Region:      {data.get('country_code')} (Series: {data.get('card_series')})\")\n",
    "#             print(f\"Name:        {data.get('given_names')} {data.get('surname')}\")\n",
    "#             print(f\"ID Number:   {data.get('document_number')}\")\n",
    "            \n",
    "#             print(f\"Personal #:  {data.get('personal_number')}\")\n",
    "            \n",
    "#             print(f\"DOB:         {data.get('date_of_birth')} ({data.get('sex')})\")\n",
    "#             print(f\"Address:     {data.get('address')}\")\n",
    "#         else:\n",
    "#             print(f\"Extraction Failed: {result.get('error')}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     scan_mexico_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fc8f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model s3://text_detection/2025_02_28 on device mps with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device mps with dtype torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:09<00:00,  9.26s/it]\n",
      "Recognizing Text: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:05<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Nombre\": \"FRANCO ZAIRA DELFINA\",\n",
      "    \"Domicilio\": \"COLDEFENSORES DE LA REPUBLIC\",\n",
      "    \"Clave de Elector\": \"FRBRZR94111021M900\",\n",
      "    \"CURP\": \"FABZ941110MPLRRR03\",\n",
      "    \"Fecha de Nacimiento\": \"10/11/1994\",\n",
      "    \"Secci\u00f3n\": null,\n",
      "    \"Vigencia\": \"2022-2032\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from surya.detection import DetectionPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from PIL import Image\n",
    "\n",
    "langs = [\"es\"]\n",
    "det_predictor = DetectionPredictor()\n",
    "rec_predictor = RecognitionPredictor()\n",
    "\n",
    "try:\n",
    "    from pdf2image import convert_from_path\n",
    "    pages = convert_from_path(paths['data_path']/'ine zai.pdf')\n",
    "    image_langs = [langs] * len(pages)\n",
    "    predictions = rec_predictor(pages, image_langs, det_predictor=det_predictor)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "def parse_mrz_name(text):\n",
    "    # Match the name line in MRZ (last line usually, format SURNAME<<NAME)\n",
    "    # Example: FRANCO<BRAVO<<ZAIRA<DELFINA<<<\n",
    "    mrz_name_match = re.search(r\"([A-Z<]+<<[A-Z<]+)\", text)\n",
    "    if mrz_name_match:\n",
    "        full_mrz = mrz_name_match.group(1)\n",
    "        parts = full_mrz.split('<<')\n",
    "        surnames = parts[0].replace('<', ' ').strip()\n",
    "        given_names = parts[1].replace('<', ' ').strip()\n",
    "        return f\"{given_names} {surnames}\".strip()\n",
    "    return None\n",
    "\n",
    "def extract_robust(text):\n",
    "    data = {}\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    \n",
    "    # 1. Name: Try MRZ first, then fall back to label\n",
    "    mrz_name = parse_mrz_name(text)\n",
    "    \n",
    "    name_match = re.search(r\"NOMBRE\\s*(.*?)\\s*DOMICILIO\", text, re.DOTALL | re.IGNORECASE)\n",
    "    potential_noisy_lines = []\n",
    "    if name_match:\n",
    "        name_block = name_match.group(1).strip()\n",
    "        name_lines = name_block.split('\\n')\n",
    "        label_name_parts = []\n",
    "        for l in name_lines:\n",
    "            ls = l.strip()\n",
    "            if len(ls) < 3: continue\n",
    "            # If it looks like noise or address related, keep it for later\n",
    "            if any(x in ls.lower() for x in [\"apper\", \"copport\", \"credenzial\", \"votar\", \"electoral\"]):\n",
    "                 potential_noisy_lines.append(ls)\n",
    "                 continue\n",
    "            label_name_parts.append(ls)\n",
    "        data[\"Nombre\"] = mrz_name or \" \".join(label_name_parts)\n",
    "    \n",
    "    # 2. Domicilio: Capture between labels and merge with noisy lines if they seem relevant\n",
    "    addr_match = re.search(r\"DOMICILIO\\s*(.*?)\\s*(?:CLAVE|CURP|ESTADO|REGISTRO|FECHA|SECCION|VIGENCIA)\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if addr_match:\n",
    "        addr_block = addr_match.group(1).strip()\n",
    "        # Sometimes address lines are mis-detected in the Name section\n",
    "        all_addr = potential_noisy_lines + addr_block.split('\\n')\n",
    "        # Deduplicate and clean\n",
    "        clean_addr = []\n",
    "        for l in all_addr:\n",
    "            ls = l.strip()\n",
    "            # Filter out obvious non-address noise like 'votar'\n",
    "            if ls and not any(x in ls.lower() for x in [\"votar\", \"electoral\", \"credenzial\"]):\n",
    "                if ls not in clean_addr:\n",
    "                    clean_addr.append(ls)\n",
    "        data[\"Domicilio\"] = \" \".join(clean_addr).replace('\\n', ' ')\n",
    "\n",
    "    # 3-7. Standard Fields\n",
    "    clave_match = re.search(r\"[A-Z]{6}\\d{8}[A-Z]\\d{3}\", text)\n",
    "    data[\"Clave de Elector\"] = clave_match.group(0) if clave_match else None\n",
    "    \n",
    "    curp_match = re.search(r\"[A-Z]{4}\\d{6}[A-Z]{6}\\d{2}\", text)\n",
    "    data[\"CURP\"] = curp_match.group(0) if curp_match else None\n",
    "    \n",
    "    dob_match = re.search(r\"(\\d{2}/\\d{2}/\\d{4})\", text)\n",
    "    if dob_match:\n",
    "        data[\"Fecha de Nacimiento\"] = dob_match.group(1)\n",
    "    elif data.get(\"CURP\"):\n",
    "        y, m, d = data[\"CURP\"][4:6], data[\"CURP\"][6:8], data[\"CURP\"][8:10]\n",
    "        century = \"19\" if int(y) > 30 else \"20\"\n",
    "        data[\"Fecha de Nacimiento\"] = f\"{d}/{m}/{century}{y}\"\n",
    "    \n",
    "    seccion_match = re.search(r\"(?:SECCI.N|SECONON|SECCON|SECOION)\\s*(\\d+)\", text, re.IGNORECASE)\n",
    "    data[\"Secci\u00f3n\"] = seccion_match.group(1) if seccion_match else None\n",
    "    \n",
    "    # 7. Vigencia\n",
    "    vigencia_match = re.search(r\"(\\d{4}\\s*-\\s*\\d{4})\", text)\n",
    "    data[\"Vigencia\"] = vigencia_match.group(1) if vigencia_match else None\n",
    "    \n",
    "    return data\n",
    "\n",
    "all_text = \"\\n\".join([line.text for result in predictions for line in result.text_lines])\n",
    "extracted_data = extract_robust(all_text)\n",
    "print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}